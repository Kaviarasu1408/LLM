## LLM Evaluation

- MMLU - Measuring Massive Multitask Language understanding
we have 57 test we can evaluate the LLM Performance and calculate the score
- Human assisted scoring
- using powerful LLM model to evaluate. e.g ollama basically it will compare the model response and the actual output and assign the results..